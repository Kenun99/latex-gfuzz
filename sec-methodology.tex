\section{Design}
In this section, we not only describe the design of  {\tool} but also explain what challenges we need to solve for answering the reasons behind the design choices.  

\begin{figure*}[t]
\centerline{\includegraphics[width=\textwidth]{images/GFL-overview.drawio.pdf}}
\caption{The overview of {\tool}}
\vspace{-0.1in}
\label{fig:overview}
\end{figure*}


\subsection{Overview}
Figure~\ref{fig:overview} depicts the architecture of the {\tool}, which fuzzes a smart contract in GPU with thousands of threads.  
%
The process pipeline consisting of five steps. 
%
First, given an evm bytecode, {\translator} translates it into a functional equivalent LLVM assembly, where the Ethereum APIs (e.g. SHA3 and storage accesses) are implemented in device functions to avoid CPU.
%
Second, {\wrapper} creates a GPU kernel function in LLVM IR to wrap the contract code from {\translator}, for the parallel execution in GPU. The kernel function schedules graphic memory for thousands of GPU threads, allowing all threads to independently execute with different input. The wrapped LLVM assembly would be translated into a PTX executable as the final fuzzing target. 
%
In the third step, {\runner} generates seeds and launches the PTX executable with thousands of threads at the same time. {\runner} is also equipped with incremental snapshots and coverage-based feedback to explore the smart contract deeper and faster since triggering a vulnerability in smart contracts usually requires several transactions\cite{TBD}. 

\subsection{{\runner}: High Performance Fuzzing}
Throughput indicates the number of seeds that can be tested by fuzzers in a time unit. The execution speed of the target program is the fundamental factor in fuzzing throughput\cite{fuzzan_atc}. 
Unfortunately, smart contract fuzzing suffers from serious throughput bottleneck, because smart contracts are designed to run on a virtual machine rather than a native environment. 
The blockchain virtual machine sacrifices its performance for the deterministic execution of smart contracts, in order to facilitate blockchain consensus protocols.
%
Although an alternative solution is to compile EVM into binary and then use it to execute smart contracts, (TBD).
%
Under such execution layout, the existing smart contract fuzzers have to maintain a virtual machine and a blockchain database to test every single smart contract. 
%
Although running multiply fuzzers in parallel can improve the efficiency\cite{confuzzius_eurosp,echidna_issta ,afl,angora_sp,enfuzz_sec}, where all fuzzing threads share an identical global pool of seeds, the state-of-the-art tools still hit the upper bound due to the limited CPU cores number.
%
Therefore, in terms of fundamental aspect, the existing smart contract fuzzers cannot achieve high throughput (See \S~\ref{} for more details).
%

We believe the key of high performance fuzzing is testing a smart contract in as many parallel threads as possible without relying on blockchain virtual machines. 
%
Parallel fuzzing has no concurrency requirement, because all fuzzing threads can test the smart contract independently. The only synchronization event is used to wait for the end of all fuzzing threads so that (TBD).
%
The more threads we can schedule, the higher throughput the fuzzer can achieve.
That is the reason why we choose to fuzz smart contracts on GPU. 
Different from CPU, GPU is full of stream processors, enabling running thousands of jobs in parallel. 
For example, as one of the most powerful CPU, AMD Ryzen Threadripper PRO 5995WX (\$6,499) only has 64 cores, while a NVIDIA RTX3090 (\$999) can provide 10,496 CUDA cores\footnote{The prices come from the official vendor websites.}. 
The incredible computation power of GPU is attractive for parallel fuzzing as long as we can translate a smart contracts to GPU executable, i.e., PTX\cite{ptx2021doc}. 
%
Running on CPU, {\runner} will launch a GPU device and fuzz the smart contracts with a batch of seeds. Once the GPU jobs are finished, {\runner} obtains the coverage information to guide the seed generations. 

In this section, we mainly elaborate the design and reasons of the fuzzing strategy that we choose. 
For example, to handle the transaction dependency, we enable smart contract running on GPU to create and restore snapshot for the storage variables (See \S~\ref{design:snapshot}). 
These strategies raise functional requirements to the smart contract and they can explain the design choices of the bytecode translation in \S~\ref{design:translator}.

% To benefit from feedback strategies and remain as high as possible throughput, there are two general approaches.
%
% One throughput improvement is boosting the execution of the fuzzing target. For example, AFL\cite{} enforces the fuzzing target initiate itself only once in the first fuzzing round and then clone its initiated process image to execute the remaining seeds.
%However, on the one hand, the redundant initiation is not the main computational overhead; on the other hand, a CPU can only provide limited threads ($<128$) for parallel execution.


\noindent \textbf{Parallel Execution on GPU}
Given a kernel function code, a GPU can schedule thousands of threads to execute a PTX code. 
%
Each thread copies the PTX code to its code segment and then extracts different input from CPU to produce different output in parallel. 
%
To be specific, each thread is labeled with an auto-increment ID (i.e., thread ID) and run in a specific CUDA core. 
Since the global memory is visible for all threads, we allocate a sequential memory to maintain all thread input. We pad every seed to 128 bytes so that each thread can compute the address offset of its input using its thread ID by using the equation $calldata = p + threadId * 128$, where $calldata$ points to a thread seed. 
%
Considering {\tool} is a coverage-based fuzzer, the coverage information recorded in the bitmap is the output of the executed smart contract. 
%
We adopt the above approach to map the bitmap to global memory taking thread ID as the index. 
%
In \S~\ref{sec:runner:bitmap} we will explain the details of bitmap instrumentation. 
%
To make each thread run independently, we ensure each smart contract code to run in a local context. Hence, threads do not have to wait each other.
%
% To make each thread run efficiently, we should create a coalescing memory and avoid strike access.
% Figure~\ref{} shows the data structure of memory layout.

% an example of data layout
% threadIdx = grid.x * block.x * thread.idx

% transaction size: why not use compact mode. 
% Our memory model is strided
% https://developer.nvidia.com/blog/how-access-global-memory-efficiently-cuda-c-kernels/
% aligned memory.

\noindent \textbf{Fuzzing with Transaction Dependency}
\label{design:snapshot}
Smart contract is a stateful program, which maintains states variables in its storage. Since the state variables can be part of the path constraints, some branches can only be explored by fuzzers when smart contract is set as a specific state. 
%
Figure~\ref{} shows an example, where the vulnerability in function $vul()$ can only be triggered when the state variable named $flag$ is set to $``poc"$ via executing $set(``poc")$ first. 
%
Hence, to explore more branches, existing fuzzers generate transaction sequences based on the transaction dependency\cite{confuzzie, echidna}. 
%
To be specific, they first fix one transaction and then combined it with a following transaction to generate a seed. However, they may execute duplicated transactions when fuzzing with sequence-based seeds. These redundant execution wastes the computational resource, resulting in low throughput. 
%
% Not to mention the challenge to recognize transaction sequences. 
% The existing fuzzers on smart contract find ideal transaction sequences based on the data flow of storage variables, which is still a open question. Storage is a key-value structure. The key of storage variables may be a hash value which is challenging to recognize 
% However, these approaches did not label which states are interesting but continue to find transactions based on the data flow graph. 
%
%In order to fulfill the transaction dependency,
To address this issue, we design a snapshot strategy to record interesting states of the smart contract. An interesting seed means new coverage is recorded in the bitmap. A program state executed after an interesting seed is an interesting state. 
%
Whenever we found an interesting state, we create a storage snapshot representing the program state. 
The created state snapshots are maintained in the CPU end. 
%
In the next fuzzing iteration, {\tool} can restore a selected snapshot to further test the smart contract.
%
By switching snapshots, {\tool} can allocate more energy on the interesting state to facilitate the transaction dependency without executing duplicated transactions. Moreover, we can initiate the storage with real-world data to test on-chain smart contract in any stages, hence the found payload can be still effective on mainnet. 
%
Since snapshot switches require additional data exchange between CPU and GPU, we must reduce the consumption of graphics memory, enabling {\tool} to conquer the memory latency between CPU and GPU, which is the main bottleneck in CUDA programming. 
To this end, we further design a Redirect-On-Write storage (See \S~\ref{}) to make the snapshot create and reload operations light and fast.


\noindent \textbf{Encoding States Changes into Bitmap}
\label{sec:runner:bitmap}
Traditional coverage-based fuzzing can only recognize control flow. For example, AFL uses a tuple $(id_{src}, id_{dst}$ to record an explored control flow, i.e., an edge from one basic block to another one. Whenever a basic block is executed, AFL increases one bitmap byte in the index of $(id_{src} * 2) \oplus id_{dst}$. 
% TODO
To record the side effect of states changes, we extend the bitmap as follow $state_0 \oplus ... \oplus state_n \oplus (id_{src} * 2) \oplus id_{dst}$, where $state_i$ indicates the storage states. 
Whenever the storage is updated, the bitmap can add one bit to reflect such change. 
As aforementioned before, the example in Figure~\ref{} has transaction dependency.  



\begin{figure}[t]
\begin{algorithm}[H]
\caption{Storing a storage state into the ROW snapshot.}
\label{algo:row_sstore}
\begin{algorithmic}[1]
    \Require $key$, the storage index; $val$, the storage state
    \State $Src \gets initial storage states$
    \State $Snap \gets the storage states snapshot$
    \If{$key \in \{s.key \mid s \in Snap\}$} 
        \State $Snap[key].val = val$
        \State \Return
    \EndIf
\end{algorithmic}
\end{algorithm}
\end{figure}


\begin{figure}[t]
\centerline{\includegraphics[width=0.5\textwidth]{images/GFL-async_cpy.drawio.pdf}}
\caption{Fuzzing Timelines}
\vspace{-0.1in}
\label{fig:async_cpy}
\end{figure}

\noindent \textbf{Asynchronous Fuzzing}
\label{design:asynchronous}
To the best of our knowledge, all traditional coverage-based fuzzers are implemented on CPU in synchronous mode. Each fuzzing iteration consists of three sequence steps, such as seed mutation, target program execution, and coverage bitmap analysis. 
On the one hand, target program execution cannot run until the seed variant is prepared by the fuzzers. 
On the other hand, fuzzers have to wait the target program execution ends to collect the coverage information, and then analyze it for next round fuzzing iteration. 
%
To improve the throughput, {\tool} aims to reduce the time intervals between these three steps.
%
Since GPU and CPU are two independent devices, {\runner} can submit fuzzing jobs to GPU and then immediately start the analysis of coverage information and seed mutation on CPU without the need of waiting the GPU. 
In Figure~\ref{}, we show the timelines for sequence mode (a) and asynchronous mode (b) in a three times fuzzing. 
{\tool} creates three stream pipeline to handle the three group of fuzzing jobs in asynchronous mode. 
The jobs in the same stream are highlighted in the same color. 
In the first time slot, we mutate seed on CPU only. In the next slot, we can run stream \#1 and \#2 together, which launches GPU and mutate seeds, respectively. At last, {\tool} can finish the fuzzing work in five slots, which is less than the traditional methodology (nine slots).

Moreover, asynchronous design enables {\tool} to reduce the overhead of memory latency. \cite{} analyzes the CUDA overhead and finds transferring data between CPU and GPU is time-consuming. {\tool} can invoke another streams when the memory bus of GPU is stuck to one stream job. 


\noindent \textbf{Seeds Mutation}
\label{design:mutation}
If a seed is interesting, {\runner} will mutate it to generate more (TBD). 
Each EVM smart contract has three parts of input, including callvalue, calldatasize and calldata. We encode them into one byte stream as a seed. Figure~\ref{} shows the seed structure. 
%
In \S~\ref{}, we have leveraged snapshot mechanism to select the tested function of a smart contract. 
%
In this part, we focus on mutating the function arguments. Specifically, we mutate the calldata starting from the fourth byte. 
%
As calldata is constructed following the ABI grammar, some sequence of bytes belong to the same function argument. Thus, they should be mutated together.
%
To this end, we parse the ABI and then identify the affine types between the raw calldata bytes and high-level function arguments. 
%
The mutation strategies inherit from AFL, such as bit fliping, bytes walking and havoc\cite{afl}. 
When the mutation is end, we compute a new calldatasize for the new calldata. 
Note that, we assume {\tool} has the owner privilege to test the target application, thus we set a constant as the transaction sender such as \texttt{msg.caller} and \texttt{tx.origin}.

    
\subsection{{\translator}: Functional Equivalent Program Generation}
\label{design:translator}
We rewrite the target smart contracts for various purposes, such as 1) generating PTX code to run on GPU, 2) inserting sanitizers to capture crashes, 3) instrumentation for obtain coverage information necessary. 
%
To rewrite the code more flexible and precise, we build an IR-based framework based on decide to LLVM intermediate representation.
%
Broadly speaking, there are two approaches to obtain the llvm assembly of an Ethereum smart contract: 1) Source code compilation by converting Solidity to C++ first and generate IR from clang\cite{}; 2) Binary translation from an EVM bytecode. 
We choose to use binary translation because blockchain public every smart contract and encourage nodes to execute and verify them, for satisfying consensus protocol. {\tool} can test the real-world smart contract as it is deployed. 
We exclude the source code approach because Solidity does not support LLVM and the existing Solidity to C++ parser has serious compatibility issues as Solidity grammar updates quite often. Moreover, even there exist available source code tools, developers have to recompile the target with flags, which may be opaque for the testing. 


\noindent \textbf{devirualization}
%basic block
We decide to obtain the intermediate representation of the given smart contract to generate a PTX program. 
%
EVM bytecode is a sequential of stack-based opcodes, which can be lifted to an registers-based LLVM assembly via devirualization and mem2reg\cite{}. 
We allocate an LLVM array as the EVM stack and thus EVM opcodes can be represented as memory accesses. 

\noindent \textbf{jumps recovery}
All EVM jumps such as \code{\%JUMP} and \code{\%JUMPI} are indirect jumps, which take the stack top as the jump destination. 
To recover the control flow of the smart contract bytecode, we lift EVM jumps as table jumps. 
Since an EVM jump must go to a basic block where the first opcode is \code{JUMPDEST}, we can recover the jump table by 

A table jump decides its jump destination until the GPU runtime when it loads the stack top from the emulated stack and then query

% We allocate an LLVM array as the EVM stack (denoted as \code{\%stk[]}) and thus EVM opcodes can be represented as memory accesses. We use an LLVM register named \code{\%sp} represented as the index of \code{\%stk[]}, which maintains the current stack height. For example, we can load the stack top using \code{\%stk[\%sp]}. By adjusting \code{\%sp}, we can push and pop data from the evm stack. 
% In general, \code{\%stk[]} consists of 1,024 256-bits elements, following the semantic setting of EVM.


\noindent \textbf{Simulating Environment Opcodes}
Some EVM opcodes are external interfaces of blockchain environment.
On the one hand, smart contracts can interact with blockchain environment via specific opcodes, such as TIMESTAMP for loading the timestamp and NUMBER for obtaining the current block height. 
%
Although blockchain clients provide restful APIs that we can import to lift the environment opcodes, it requires GPU to wait data from CPU and thus will sharply decrease the {\tool} throughput.
%
On the other hand, smart contract adopts big endianness rather than the little endianness used in GPU architecture. 
To run smart contracts in GPU, we need to simulate the environment opcodes inside GPU and convert the endianness. 
For each kind of environment opcodes, we create a device function:
\begin{itemize}
    \item `get' approaches: return constants
    \item hash function: implement the keccak256  method;
    \item storage accesses: read and store data from a ROW snapshot (See \S~\ref{});
    \item load input data: load data from the CPU in little endianness.
    \item memory operations: read and store data from \code{\%mem} in little endianness.
\end{itemize}

Note that, each thread only access the local memory to avoid threads synchronization.

\noindent\textbf{Storage}
{\tool} can perform snapshot reload and creation operations fast and light. This design is based on our observation that a transaction usually only modifies specific storage variables. Therefore, the states of a smart contract share parts the same content. That is the reason why we create a snapshot-based storage. 
%
Given an initial storage, we schedule thousands GPU threads to test the state. We store the initial storage in global memory as the source volume, broadcasting its content to every thread. Every thread creates a ROW snapshot in its local memory to avoid synchronization. If the seed is interesting, we export the storage snapshot to CPU and combine it with the source volume to build a full storage snapshot.   
%
We first initiate a source volume as the initial storage of the smart contract, and then create a Redirect-on-write (ROW) snapshot for each fuzzing thread. The snapshot maintains all storage states of the given smart contract, enabling each GPU thread to use minor memory to record the states changes. 
%
Whenever the smart contract stores a state into its storage (i.e., \code{SSTORE}), we save the state in the snapshot. As for the storage loading activities (i.e., \code{SLOAD}), we first enquiry from the snapshot and then the source volume. 
If the seed is interesting, we export the storage snapshot from GPU to CPU. 
We can reload a full storage by combined the exported snapshot and the source volume together. The full storage will become the initial storage in next fuzzing iteration.